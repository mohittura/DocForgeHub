# DocForgeHub â€” Codebase Architecture & Approach

## ğŸ¯ Project Overview

**DocForgeHub** is an intelligent document generation and management system that:
- Extracts business documents from Notion
- Generates comprehensive Q&A from documents using LLMs
- Stores Q&As in MongoDB with department/category organization
- **Analyses schema coverage gaps and generates targeted questions to fill them**
- Generates polished, professional business documents from user answers using an agentic workflow
- Provides a Streamlit UI for document generation and management

---

## ğŸ—ï¸ Architecture Stack

### Technology Stack
- **LLM Provider**: Groq (Kimi-k2 instruct for document generation; Llama-3.3-70b for gap analysis)
- **Agent Framework**: LangGraph (for multi-step workflows)
- **Backend API**: FastAPI (async, CORS-enabled)
- **Database**: MongoDB (async motor driver)
- **Frontend**: Streamlit
- **Document Management**: Notion API
- **Language**: Python

### Core Dependencies
- `langchain-groq` â€” LLM integration with Groq
- `langgraph` â€” State graph-based agent orchestration
- `fastapi` â€” REST API backend
- `motor` â€” Async MongoDB driver
- `streamlit` â€” Interactive UI
- `notion-client` â€” Notion API integration

---

## ğŸ“Š System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      STREAMLIT UI FRONTEND                       â”‚
â”‚  (Department / Document / Core Q&A / Gap Q&A / Generated View)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚ HTTP REST
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     FASTAPI BACKEND (Port 8000)                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ GET  /departments         â†’ List all departments           â”‚ â”‚
â”‚  â”‚ GET  /document-types      â†’ List docs for department       â”‚ â”‚
â”‚  â”‚ GET  /questions           â†’ List Q&As (incl. gap Qs)       â”‚ â”‚
â”‚  â”‚ GET  /required-section    â†’ Fetch schema from MongoDB      â”‚ â”‚
â”‚  â”‚ POST /gap-questions  â˜…NEW â†’ Analyse gaps + generate Qs     â”‚ â”‚
â”‚  â”‚ POST /save-questions â˜…NEW â†’ Persist gap Qs to MongoDB      â”‚ â”‚
â”‚  â”‚ POST /generate            â†’ Trigger agentic document gen   â”‚ â”‚
â”‚  â”‚ GET  /get_all_urls        â†’ Retrieve Notion page URLs      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                            â”‚                                     â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚          â–¼                 â–¼                 â–¼                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  Agent Graph â”‚   â”‚   MongoDB    â”‚   â”‚ Notion API   â”‚        â”‚
â”‚  â”‚   (Document  â”‚   â”‚    Client    â”‚   â”‚  (Page URLs) â”‚        â”‚
â”‚  â”‚  Generation) â”‚   â”‚              â”‚   â”‚              â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Data Flow Layers

### Layer 1: Data Extraction & Organization
**Files**: `automations/ques_automation.py`, `automations/automation.py`

1. **Notion Content Extraction** (`NotionContentExtractor`)
   - Connects to Notion via API
   - Recursively retrieves child pages organized by headings
   - Extracts markdown content from pages

2. **LangGraph-based Question Generation** (`GroqLangGraphQuestionGenerator`)
   - Implements a multi-node state graph workflow
   - Nodes:
     - `_analyze_and_detect`: Analyzes document structure & content patterns
     - `_generate_questions`: LLM-powered question generation
     - `_simple_validate`: Rule-based validation (no LLM call)
   - Resilient API calling with fallback across multiple Groq API keys
   - Outputs structured JSON Q&A files

3. **Output Organization**
   - Questions saved to `generated_questions/` by department
   - Structured as: `generated_questions/{department}/{document_name}_questions.json`

---

### Layer 2: Answer Field Addition & Filtering
**Files**: `automations/add_answer_field.py`

1. **QuestionAnswerProcessor**
   - Reads generated question files
   - Adds empty `answer` field to each question
   - Organizes by topics/categories

2. **Output Structure**
   - Final Q&As saved to `final_filtered_QAs/{department}/`
   - Format: `{document_name}_questions.json` with answer fields

---

### Layer 3: MongoDB Integration
**Files**: `automations/mongo_auto.py`, `api/db.py`

1. **DepartmentBasedMongoDBIntegration**
   - Reads Q&A files from `final_filtered_QAs/`
   - Batch inserts into MongoDB
   - Creates collections:
     - `document_qas`: Contains all Q&A pairs organized by department/document
     - `required_section`: Stores document schemas/structure requirements

2. **MongoDB Schema**
   ```python
   document_qas: {
       department: { code, name, slug },
       document_type: str,
       document_name: str,
       question: str,
       answer: str,
       category: str,
       category_order: int,
       question_order: int,
       answer_type: str,           # "text" | "select" | "multi_select" | "structured_list"
       options: list,
       is_gap_question: bool,      # â˜… NEW â€” True for AI-generated gap questions
       section_covered: str,       # â˜… NEW â€” which schema section this covers
       answered_at: datetime       # â˜… NEW â€” timestamp when gap Q was answered & saved
   }

   required_section: {
       department: str,
       document_name: str,
       sections: [{ title, type, subsections/columns, ... }]
   }
   ```

3. **Async Database Connection** (`api/db.py`)
   - Singleton motor AsyncIOMotorClient
   - Lazy initialization on first access
   - Proper lifecycle management with FastAPI lifespan

---

### Layer 4: FastAPI Backend Orchestration
**File**: `api/main.py`

**Key Endpoints**:

| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/departments` | GET | Returns sorted list of departments from MongoDB |
| `/document-types` | GET | Returns document types for a given department |
| `/questions` | GET | Returns Q&A pairs (core + saved gap questions) for a document type |
| `/required-section` | GET | Fetches document schema/structure template |
| `/gap-questions` | POST | â˜… NEW: Analyse schema coverage gaps, return targeted questions |
| `/save-questions` | POST | â˜… NEW: Persist answered gap questions to MongoDB |
| `/generate` | POST | Triggers LangGraph agent for document generation |
| `/get_all_urls` | GET | Retrieves all Notion page URLs (for history) |

**`POST /gap-questions` â€” Two-stage logic**:
```
1. Check MongoDB: are gap questions already saved for this document_type?
      YES â†’ return them immediately (source: "cache", no LLM call)
      NO  â†’ run lightweight LLM gap analysis (source: "generated")
```
This caching layer is the primary mechanism that prevents repeated LLM
calls for the same document type across sessions and users.

**`POST /save-questions` â€” Upsert with deduplication**:
- Upserts on `(document_type, question, is_gap_question=True)`
- Sets `question_order` to 1000+ so gap questions sort after core ones
- Sets `category_order: 999` â†’ always rendered last in the UI

**CORS Configuration**:
- Allows requests from Streamlit on `localhost:8501` and `127.0.0.1:8501`

---

### Layer 5: LangGraph Agent for Document Generation
**File**: `agent/agent_graph.py`

**Purpose**: Transforms user answers into professional, schema-compliant documents

**Two LLMs are now used**:
| Model | Role | Why |
|-------|------|-----|
| `moonshotai/kimi-k2-instruct-0905` | Primary â€” document generation, quality review, fixes | Best output quality for long-form prose |
| `llama-3.3-70b-versatile` | Secondary â€” schema gap analysis only | Faster, cheaper, sufficient for structured JSON output |

**Agent State** (`AgentState`):
```python
# Inputs
department: str
document_type: str
questions_and_answers: list[dict]
required_section: dict

# Intermediates/Outputs
gap_questions: list[dict]       # â˜… NEW: AI-generated questions for uncovered sections
supplementary_content: str      # Context notes for the document LLM about gaps
system_prompt: str              # Full LLM prompt
generated_document: str         # Final output
quality_scores: dict            # LLM quality metrics
quality_issues: list[str]       # Validation failures
quality_suggestions: list[str]  # Improvement suggestions
retry_count: int                # Retry attempts
status: str                     # "generating" | "passed" | "failed"
```

**5-Node Workflow**:

```
START
  â”‚
  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. analyze_schema_gaps            â˜… NEW NODE  â”‚
â”‚  â€¢ Compares schema sections vs Q&A answers   â”‚
â”‚  â€¢ Uses lightweight Llama-3.3-70b LLM        â”‚
â”‚  â€¢ Outputs: gap_questions (JSON array)        â”‚
â”‚  â€¢ Also writes supplementary_content notes   â”‚
â”‚    so doc LLM knows gaps exist               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. build_prompt              â”‚
â”‚  (Format Q&As + schema)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. generate_document         â”‚
â”‚  (Primary LLM â€” Kimi-k2)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. quality_gate              â”‚
â”‚  (Validate structure)        â”‚
â”‚  - Table-only: Deterministic â”‚
â”‚  - Mixed: LLM review         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
          â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
          â”‚          â”‚
       PASS       FAIL
          â”‚          â”‚
        END    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚ 5. fix_document â”‚
               â”‚  (Retry & fix)  â”‚
               â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                (loop back to
                 quality_gate)
```

**Node Descriptions**:

1. **`analyze_schema_gaps`** â˜… NEW (replaces `fill_schema_gaps`)
   - Sends schema + existing Q&As to the lightweight `question_gen_llm`
   - LLM returns a JSON array: `[{question, category, answer_type, section_covered}]`
   - Uncovered sections get a placeholder note in `supplementary_content` so
     the document LLM knows to flag them rather than silently skip
   - Gap questions are returned in `state["gap_questions"]` â€” surfaced in UI and
     optionally saved to MongoDB
   - **Key difference from the old `fill_schema_gaps`**: instead of hallucinating
     content to fill gaps itself, it asks the *user* for missing information

   Old approach:
   ```
   fill_schema_gaps â†’ primary LLM synthesizes filler content (bypasses user)
   ```
   New approach:
   ```
   analyze_schema_gaps â†’ lightweight LLM asks the right questions
                       â†’ user provides real answers
                       â†’ better document quality, no hallucination
   ```

2. **`build_prompt`** â€” unchanged
   - Formats Q&As into readable text blocks (organized by category)
   - Formats schema into markdown structure guide
   - Constructs system prompt with LLM instructions
   - Detects table-only vs mixed schemas and selects appropriate prompt template

3. **`generate_document`** â€” unchanged
   - Calls primary Groq LLM with formatted prompt + system instructions
   - Returns raw markdown document

4. **`quality_gate`** â€” unchanged
   - **Table-only schemas**: Deterministic validation
     - Extracts markdown table from output
     - Verifies column headers match schema exactly
     - Auto-fixes by extracting only table + heading
   - **Mixed schemas**: LLM-based review with rule-based fallback
     - Validates structure, completeness, professionalism
     - Returns quality scores & issues

5. **`fix_document`** â€” unchanged
   - If quality gate fails, re-prompts primary LLM with corrections
   - Increments retry counter
   - Loops back to `quality_gate` for re-validation

**Standalone utility** â€” `analyze_gaps_only()`:
- Runs only node 1 without the full document generation pipeline
- Used by `POST /gap-questions` for on-demand pre-generation gap analysis

---

### Layer 6: Streamlit Frontend UI
**File**: `ui/streamlit_uidemo.py`

**UI Flow**:
1. **Left Sidebar**
   - Department selector (dropdown)
   - Document selector (dropdown)
   - Generation history (clickable links to Notion pages)
   - Auto-clears gap questions when document selection changes

2. **Main Area** (Two-column layout)
   - **Left Column**: Q&A Panel
     - Core questions (from MongoDB, rendered by category)
     - **Gap Questions section** â˜… NEW (two sources, visually unified):
       - *MongoDB-persisted gap questions* (`is_gap_question: True`) â€” loaded
         automatically with `/questions`, rendered identically to core questions
         but with an `AI` badge
       - *Session gap questions* â€” freshly generated via `POST /gap-questions`,
         shown with a "ğŸ’¾ Save gap questions" button
     - "ğŸ” Analyse schema gaps" button â€” triggers on-demand gap analysis
     - "âš¡ Generate Document" button â€” sends all answers (core + gap) to `/generate`
   - **Right Column**: Document Editor
     - Displays generated markdown
     - Editable textarea for refinements
     - Rendered preview (collapsible)
     - Publish to Notion button

3. **Gap Question Lifecycle in the UI**:
```
User clicks "ğŸ” Analyse schema gaps"
  â”‚
  â–¼
POST /gap-questions
  â”œâ”€â”€ source: "cache" â†’ display immediately, no spinner delay
  â””â”€â”€ source: "generated" â†’ ~10s spinner, then display

User fills in gap answers
  â”‚
  â–¼
User clicks "ğŸ’¾ Save gap questions"
  â”‚
  â–¼
POST /save-questions â†’ upsert to MongoDB
  â”‚
  â–¼
questions cache cleared â†’ next load includes gap Qs automatically
```

4. **Answer payload sent to `/generate`**:
   - Core Q&A answers (`st.session_state.answers`)
   - MongoDB-persisted gap Q answers (already in core answers dict)
   - Session gap Q answers (`st.session_state.gap_answers`)
   - All merged into a single `questions_and_answers` list

5. **Session State Management**:
   ```python
   history        # Notion page URLs
   answers        # Core + MongoDB-gap question answers {key: value}
   gap_answers    # Session gap question answers {key: value}
   gap_questions  # Current session gap questions list
   gap_source     # "cache" | "generated"
   gap_doc_type   # document_type the gap questions belong to (for auto-clear)
   markdown_doc   # Generated document text
   is_generating  # Button lock flag
   is_analyzing   # Button lock flag
   is_saving      # Button lock flag
   ```

**API Helpers** (with caching):
- `get_departments_from_fastapi()` â€” TTL 300s
- `get_document_types_from_fastapi(department)` â€” TTL 300s
- `get_questions_from_fastapi(document_type)` â€” TTL 300s (cleared after save)
- `get_notionpage_urls_from_fastapi()` â€” TTL 600s
- `call_gap_questions_endpoint()` â€” POST, no cache (always fresh)
- `call_save_questions_endpoint()` â€” POST, no cache
- `call_generate_endpoint()` â€” POST, no cache

**Shared widget renderer** â€” `render_question_widget()`:
- Single function handles all `answer_type` variants: `text`, `structured_list`,
  `select`, `multi_select`
- Accepts `is_gap=True` to inject an `AI` badge without changing widget behaviour
- Eliminates duplicated widget logic between core and gap question rendering

---

## ğŸ“ File Structure

```
DocForgeHub/
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ agent_graph.py           # 5-node LangGraph agent + orchestration
â”‚   â”‚                              â˜… analyze_schema_gaps replaces fill_schema_gaps
â”‚   â”‚                              â˜… analyze_gaps_only() utility added
â”‚   â”œâ”€â”€ prompts.py               # System prompt templates & formatting
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ main.py                  # FastAPI endpoints
â”‚   â”‚                              â˜… POST /gap-questions added
â”‚   â”‚                              â˜… POST /save-questions added
â”‚   â”œâ”€â”€ db.py                    # MongoDB connection (async motor)
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ automations/
â”‚   â”œâ”€â”€ ques_automation.py       # Question generation with LangGraph
â”‚   â”œâ”€â”€ automation.py            # Notion content extraction
â”‚   â”œâ”€â”€ add_answer_field.py      # Add answer fields & organize
â”‚   â”œâ”€â”€ mongo_auto.py            # MongoDB batch upload
â”‚   â”œâ”€â”€ required_sections_automation.py  # Schema upload to MongoDB
â”‚   â”œâ”€â”€ clean_reorder.py         # Data cleanup utilities
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ streamlit_uidemo.py     # Streamlit frontend
â”‚                                  â˜… Gap questions panel added
â”‚                                  â˜… render_question_widget() helper added
â”‚                                  â˜… gap_answers session state added
â”‚
â”œâ”€â”€ document_and_questions/
â”‚   â”œâ”€â”€ final_filtered_QAs/      # Final Q&As by department
â”‚   â”‚   â”œâ”€â”€ 1._Product_Management/
â”‚   â”‚   â”œâ”€â”€ 2._Engineering__Software_Development/
â”‚   â”‚   â”œâ”€â”€ ... (10 departments)
â”‚   â”‚   â””â”€â”€ 10._Finance/
â”‚   â”‚
â”‚   â””â”€â”€ notion_documents/        # Extracted Notion docs
â”‚       â””â”€â”€ ... (same structure)
â”‚
â”œâ”€â”€ progress.md                  # Development log
â””â”€â”€ .env                         # Credentials (MongoDB, Groq, Notion)
```

---

## ğŸ”‘ Design Patterns & Approaches

### 1. **State Machine via LangGraph**
- Multi-step workflow modeled as directed acyclic graph (DAG)
- Each node is a pure function: `State â†’ dict`
- Conditional routing based on quality gate results
- Built-in retry loop (`fix_document` â†’ `quality_gate`)

### 2. **Async-First Architecture**
- FastAPI with async/await throughout
- Motor (async MongoDB driver)
- Graceful lifespan management (app startup/shutdown)

### 3. **Schema-Driven Generation**
- Documents strictly follow MongoDB `required_section` schema
- Two validation modes:
  - **Deterministic** (table-only): Regex + structural validation
  - **LLM-based** (mixed): Semantic validation with quality scoring

### 4. **User-In-The-Loop Gap Filling** â˜… NEW
- Old approach: LLM synthesised supplementary content autonomously (hallucination risk)
- New approach: Lightweight LLM identifies gaps â†’ generates targeted questions â†’ user provides real answers
- Gap questions are persisted to MongoDB so future users benefit immediately
- Cache-first design: gap questions are generated at most once per document type

### 5. **Two-LLM Architecture** â˜… NEW
- **Primary LLM** (Kimi-k2): Long-form document generation, quality review, fixes
- **Secondary LLM** (Llama-3.3-70b): Schema gap analysis, structured JSON output
- Separation keeps the heavy model focused on prose quality and the light model on analysis

### 6. **Gap Question Caching via MongoDB** â˜… NEW
- `POST /gap-questions` checks MongoDB before calling any LLM
- Once a document type's gaps are analysed and saved, subsequent requests
  return cached results instantly â€” no further LLM calls needed
- Scales gracefully: the question-generation load is O(1) per document type, not O(users)

### 7. **Resilient API Calls**
- Multiple Groq API keys for fallback
- Retry logic with exponential backoff
- Clear error messages and logging

### 8. **Batch Processing Automation**
- Command-line tools for bulk operations:
  - Extract questions from Notion
  - Add answer fields
  - Upload to MongoDB
  - Manage schemas
- Interactive confirmation prompts
- Progress tracking and summaries

### 9. **Data Organization by Taxonomy**
- Hierarchical: Department â†’ Document Type â†’ Q&A
- MongoDB indexing for fast queries
- Streamlit caching for performance

---

## ğŸš€ Execution Flow (Complete User Journey)

### Setup Phase (One-time)
1. Extract documents from Notion â†’ `notion_documents/`
2. Generate questions via LangGraph â†’ `generated_questions/`
3. Add answer fields â†’ `final_filtered_QAs/`
4. Upload to MongoDB (documents + schemas)

### Runtime Phase (Per Document Generation)
1. **Streamlit UI**: User selects department + document
2. **API**: Fetch Q&As + schema from MongoDB (includes any saved gap questions)
3. **Streamlit**: User fills in core answers
4. *(Optional)* **User clicks "ğŸ” Analyse schema gaps"**:
   - `POST /gap-questions` â†’ checks MongoDB cache first
   - Returns gap questions; user fills in answers
   - User clicks "ğŸ’¾ Save gap questions" â†’ `POST /save-questions` â†’ persisted for future users
5. **User clicks "âš¡ Generate Document"** â†’ `POST /generate`:
   - FastAPI receives all answers (core + gap)
   - Calls `run_agent()` with Q&As + schema
6. **Agent Graph**:
   - `analyze_schema_gaps` â†’ `build_prompt` â†’ `generate_document`
   - `quality_gate` (validate) â†’ `fix_document` (if needed)
   - Gap questions from the agent also surfaced in UI if not already loaded
7. **Response**: Return generated markdown + quality metrics + any new gap questions
8. **Streamlit**: Display markdown + allow edits + show quality scores
9. **Publish**: Optional upload to Notion

---

## ğŸ› ï¸ Key Technologies & Why

| Component | Technology | Why |
|-----------|-----------|-----|
| Primary LLM | Groq + Kimi-k2 | Best prose quality, supports long-form generation |
| Gap Analysis LLM | Groq + Llama-3.3-70b | Fast, cheap, excellent at structured JSON output |
| Agent Orchestration | LangGraph | Deterministic multi-step workflows, built-in state management |
| API | FastAPI | Async support, auto docs, CORS middleware |
| Database | MongoDB | Flexible schema, fast aggregation, upsert support |
| Frontend | Streamlit | Rapid prototyping, caching built-in, minimal code |
| Async Driver | Motor | Non-blocking DB operations, FastAPI integration |

---

## ğŸ“ˆ Quality Assurance

### Quality Gate Validations
1. **Structural**: Document follows schema sections exactly
2. **Table Validation**: Markdown tables have correct columns
3. **Completeness**: All required sections present
4. **Professionalism**: LLM scores readability, clarity, tone
5. **Suggestions**: Auto-generated improvement tips

### Retry Mechanism
- Up to 2 retries to fix document (3 total attempts)
- Each retry receives specific failure feedback
- If all retries fail, returns partial document with `status: "failed"`

### Gap Coverage
- Schema sections not addressed by core questions are flagged
- Users are prompted with targeted gap questions before generation
- Gap answers are included in the full Q&A payload â€” resulting in higher
  completeness scores from the quality gate

---

## ğŸ” Security & Configuration

### Environment Variables (.env)
```
GROQ_API_KEY (and _2 through _7)
MONGODB_CONNECTION_STRING
MONGODB_DATABASE
NOTION_API_KEY
```

### CORS Policy
- Restricts API to Streamlit frontend (localhost:8501)
- Prevents unauthorized cross-origin requests

---

## ğŸ“Š Summary Table

| Layer | Purpose | Key Files | Tech |
|-------|---------|-----------|------|
| **1. Extraction** | Extract from Notion, generate Q&As | `ques_automation.py` | LangGraph, Notion API |
| **2. Enrichment** | Add answer fields, organize | `add_answer_field.py` | Python utilities |
| **3. Storage** | Persist to MongoDB | `mongo_auto.py` | MongoDB, Motor |
| **4. API** | Serve data & trigger generation | `main.py` | FastAPI, Motor |
| **5. Agent** | Analyse gaps + generate documents | `agent_graph.py` | LangGraph, Groq (Ã—2) |
| **6. Frontend** | User interface | `streamlit_uidemo.py` | Streamlit |

---

## ğŸ“ Architectural Highlights

âœ… **Modular Design**: Each layer independently testable  
âœ… **State-Driven**: LangGraph ensures deterministic workflows  
âœ… **Scalable**: Async operations, MongoDB indexing  
âœ… **Resilient**: Multi-retry loops, API key fallbacks  
âœ… **Professional Output**: Content elevation + quality gates  
âœ… **User-in-the-Loop**: Gap questions ask users instead of hallucinating  
âœ… **Cache-First Gap Analysis**: O(1) LLM calls per document type, not per user  
âœ… **User-Friendly**: Streamlit UI with caching & real-time feedback  

---

**Last Updated**: February 19, 2026  
**Architecture Version**: 1.2